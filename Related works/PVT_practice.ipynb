{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fc38e11",
   "metadata": {},
   "source": [
    "## Process of PVT \n",
    "\n",
    "\n",
    "참고 : https://github.com/whai362/PVT/blob/v2/detection/pvt.py\n",
    "\n",
    "\n",
    "class pvt_tiny(PyramidVisionTransformer)의 1 iteration에 대해 (stage 1)\n",
    "\n",
    "전반적인 연산 흐름, output의 크기 등을 이해하는 것에 초점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4971734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from timm.models.layers import DropPath, to_2tuple, trunc_normal_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0f155f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "in_chans = 3\n",
    "\n",
    "patch_size = 4\n",
    "\n",
    "embed_dims = [64, 128, 320, 512]\n",
    "num_heads = [1, 2, 5, 8]\n",
    "mlp_ratios = [8, 8, 4, 4],\n",
    "qkv_bias = True\n",
    "depths = [2, 2, 2, 2],\n",
    "sr_ratios = [8, 4, 2, 1]\n",
    "drop_rate = 0.0\n",
    "drop_path_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a63d8d",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ff3f8a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 224, 224)  # B, C, H, W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920dcc40",
   "metadata": {},
   "source": [
    "### Patch Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0d5fc883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_size = to_2tuple(img_size)\n",
    "# patch_size = to_2tuple(patch_size)\n",
    "\n",
    "# print(img_size)\n",
    "# print(patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2c0d367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 64  # embed_dims[0]\n",
    "proj = nn.Conv2d(in_chans, embed_dim , kernel_size=patch_size, stride=patch_size)\n",
    "norm = nn.LayerNorm(embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fcd4f2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 56, 56])\n",
      "torch.Size([1, 64, 3136])\n",
      "torch.Size([1, 3136, 64])\n"
     ]
    }
   ],
   "source": [
    "print(proj(x).shape)\n",
    "print(proj(x).flatten(2).shape)  \n",
    "print(proj(x).flatten(2).transpose(1, 2).shape)  # 4x4 patch가 총 3136개 존재 : (B, N, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7984cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = proj(x).flatten(2).transpose(1, 2)\n",
    "x = norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "95ed4b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3136, 64])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9498c90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patches = 3136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "67bc8be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "60e7b916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 56\n"
     ]
    }
   ],
   "source": [
    "H = img_size // patch_size\n",
    "W = img_size // patch_size\n",
    "\n",
    "print(H, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f62b7e3",
   "metadata": {},
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f5f1f382",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n",
    "pos_drop = nn.Dropout(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "543140e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3136, 64])\n"
     ]
    }
   ],
   "source": [
    "print(pos_embed.shape)  # x와 동일한 shape (Patch Embedding 결과에 더해짐)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4fe314",
   "metadata": {},
   "source": [
    "### Spatial Reduction Attention\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/145922486-e2dded10-1c63-4230-b5f0-faea32b6268e.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "447b64bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 64  # embed_dims[0]\n",
    "num_head = num_heads[0]\n",
    "mlp_ratio = mlp_ratios[0]\n",
    "sr_ratio = sr_ratios[0]  # 8\n",
    "qkv_bias = True\n",
    "drop = drop_rate\n",
    "qk_scale = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9acc4387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_dim = dim // num_head\n",
    "head_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d2b54b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = nn.Linear(dim, dim, bias=qkv_bias)  # Query\n",
    "kv = nn.Linear(dim, dim * 2, bias=qkv_bias)  # Key, Value\n",
    "attn_drop = nn.Dropout(0)\n",
    "proj = nn.Linear(dim, dim)\n",
    "proj_drop = nn.Dropout(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2f95cd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr_ratio를 사용하여 Key, Value의 공간 차원 감소 (spatial reduction)\n",
    "sr = nn.Conv2d(dim, dim, kernel_size=sr_ratio, stride=sr_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e5fe758d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3136 64\n"
     ]
    }
   ],
   "source": [
    "B, N, C = x.shape\n",
    "print(B, N, C)  # Batch, Len of sequence, Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ca5a49b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3136, 64])\n",
      "torch.Size([1, 3136, 1, 64])\n",
      "torch.Size([1, 1, 3136, 64])\n"
     ]
    }
   ],
   "source": [
    "print(q(x).shape)\n",
    "print(q(x).reshape(B, N, num_head, C).shape)  \n",
    "print(q(x).reshape(B, N, num_head, C).permute(0, 2, 1, 3).shape)  # B, H, N, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3ee3201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = q(x).reshape(B, N, num_head, C).permute(0, 2, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e3cd3046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3136, 64])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape  # input tensor x와 동일한 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5c2c0a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3136, 64])\n",
      "torch.Size([1, 64, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "x_ = x.permute(0, 2, 1).reshape(B, C, H, W)\n",
    "print(x.shape)\n",
    "print(x_.shape)  # B, C, H, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ec93ca16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 7, 7])\n",
      "torch.Size([1, 64, 49])\n",
      "torch.Size([1, 49, 64])\n"
     ]
    }
   ],
   "source": [
    "print(sr(x_).shape)  # Spatial Reduction (56x56x64) -> ((56x56)/8^2) x 64 = 49 x 64\n",
    "print(sr(x_).reshape(B, C, -1).shape)\n",
    "print(sr(x_).reshape(B, C, -1).permute(0, 2, 1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c8fd1696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 49, 64])\n"
     ]
    }
   ],
   "source": [
    "x_ = sr(x_).reshape(B, C, -1).permute(0, 2, 1)\n",
    "print(x_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "288b9ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 49, 128])\n",
      "torch.Size([1, 49, 2, 1, 64])\n",
      "torch.Size([2, 1, 1, 49, 64])\n"
     ]
    }
   ],
   "source": [
    "print(kv(x_).shape)\n",
    "print(kv(x_).reshape(B, -1, 2, num_head, C // num_head).shape)  # B, N, 2(k, v), H, C\n",
    "print(kv(x_).reshape(B, -1, 2, num_head, C // num_head).permute(2, 0, 3, 1, 4).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5729d7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kv = kv(x_).reshape(B, -1, 2, num_head, C // num_head).permute(2, 0, 3, 1, 4)\n",
    "k, v = kv[0], kv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "dc28f534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3136, 64])\n",
      "torch.Size([1, 1, 49, 64])\n",
      "torch.Size([1, 1, 49, 64])\n"
     ]
    }
   ],
   "source": [
    "print(q.shape)  # B, H, N, C\n",
    "print(k.shape)  # B, H, N, C\n",
    "print(v.shape)  # B, H, N, C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cd719b",
   "metadata": {},
   "source": [
    "query는 (56x56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "26c4bf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 64, 49])\n",
      "torch.Size([1, 1, 3136, 49])\n"
     ]
    }
   ],
   "source": [
    "print(k.transpose(-2, -1).shape)\n",
    "print((q @ k.transpose(-2, -1)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6b44e875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3136, 49])\n"
     ]
    }
   ],
   "source": [
    "attn = (q @ k.transpose(-2, -1))\n",
    "print(attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2881df8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3136, 49])\n"
     ]
    }
   ],
   "source": [
    "attn = attn.softmax(dim=-1)\n",
    "print(attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e40272cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3136, 49])\n"
     ]
    }
   ],
   "source": [
    "attn = attn_drop(attn)\n",
    "print(attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9a378c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3136, 64])\n",
      "torch.Size([1, 3136, 1, 64])\n",
      "torch.Size([1, 3136, 64])\n"
     ]
    }
   ],
   "source": [
    "print((attn @ v).shape)\n",
    "print((attn @ v).transpose(1, 2).shape)\n",
    "print((attn @ v).transpose(1, 2).reshape(B, N, C).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6a322686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3136, 64])\n"
     ]
    }
   ],
   "source": [
    "x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "dab0fa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3136, 64])\n"
     ]
    }
   ],
   "source": [
    "x = proj(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c038a897",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d63c370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_features = 64\n",
    "in_features = 64\n",
    "hidden_features = 64\n",
    "act_layer=nn.GELU\n",
    "fc1 = nn.Linear(in_features, hidden_features)\n",
    "act = act_layer()\n",
    "fc2 = nn.Linear(hidden_features, out_features)\n",
    "drop = nn.Dropout(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3e1198e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fc1(x)\n",
    "x = act(x)\n",
    "x = drop(x)\n",
    "x = fc2(x)\n",
    "x = drop(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "126fe70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3136, 64])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1e06e8",
   "metadata": {},
   "source": [
    "### Output of stage1\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/145932869-41e889e8-601d-4598-a67c-8ff9c90d24cb.png)\n",
    "\n",
    "<br/>\n",
    "\n",
    "* 224 x 224 x 3 이미지를 입력으로 받아 56 x 56 x 64의 feature map 출력\n",
    "\n",
    "\n",
    "* stage2의 입력으로 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1c569b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 56, 56])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(B, H, W, -1).permute(0, 3, 1, 2).shape  # F1 : H/4 x W/4 x C1 = 56 x 56 x 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b6d994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
